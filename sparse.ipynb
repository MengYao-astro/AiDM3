{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM Assignment 3 Group 81\n",
    "### Meng Yao (yao@strw.leidenuniv.nl) and Michael Keim (keim@strw.leidenuniv.nl)\n",
    "##  Part 3: Intial PageRank Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must load IDs of page link origins and targets and all unqiue IDS generated in prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_From = np.load('ID_From.npy')\n",
    "ID_To = np.load('ID_To.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must find unique page IDs. These pages will be both the rows and columns of our matrix M which we will use to simulate random walks across nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_Unique = np.unique(np.concatenate((ID_From, ID_To), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we count nonzero outgoing links. This will serve as the denominator for the columns of our matrix M, making an even distribution 1 / (the total outgoing count) for connected nodes as the proability of going to the page of a row from the page of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_Outgoing_Nonzero, ID_Outgoing_Count = np.unique(ID_From, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our matrix M as a sparse matrix. We initalize with ones (next step is normalization) in the rows and columns of destination and current page nodes as specified in ID_To and ID_From."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = csc_matrix((np.ones(len(ID_From)), (ID_To, ID_From)), shape=(len(ID_Unique), len(ID_Unique)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalize by dividing columns the total number of outgoing node connections. We will use 1 if the node is a dead end. The result of the division will still be 0, as there would be no entries for the column in our sparse matrix, but we will avoid nans by doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm = np.ones(len(ID_Unique))\n",
    "Norm[ID_Outgoing_Nonzero] = ID_Outgoing_Count\n",
    "val = np.repeat(Norm, M.getnnz(axis=0))\n",
    "M.data /= val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a vector v with an entry for each page and an even inital distribution across all pages. In the end this will measure the page importance if we properly use the PageRank update rule and converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.ones(len(ID_Unique))/len(ID_Unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a vector to represent teleportation, a method to attempt to correct for dead ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.8\n",
    "v_teleport = (1-beta)*np.ones(len(ID_Unique))/len(ID_Unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we iterate to creat v_new, which converges fairly quickly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.04970154e-03 4.74910361e-04 3.16997638e-05 8.76108822e-06\n",
      " 1.12268880e-05 1.16729133e-05 1.20460437e-05 1.21650927e-05\n",
      " 1.22272553e-05 1.22559916e-05 1.22724479e-05 1.22818350e-05\n",
      " 1.22881334e-05 1.22921225e-05 1.22950448e-05 1.22970072e-05\n",
      " 1.22985003e-05 1.22995409e-05 1.23003446e-05 1.23009196e-05\n",
      " 1.23013663e-05 1.23016921e-05 1.23019456e-05 1.23021334e-05\n",
      " 1.23022796e-05]\n"
     ]
    }
   ],
   "source": [
    "iterations = 25\n",
    "v_new = np.zeros(len(ID_Unique))\n",
    "MSE = np.zeros(iterations) # To store error\n",
    "for i in range(iterations):\n",
    "        v_new = beta * M * v + v_teleport\n",
    "        MSE[i] = np.sum((v - M * v)**(2.))\n",
    "        v = v_new\n",
    "print(MSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
